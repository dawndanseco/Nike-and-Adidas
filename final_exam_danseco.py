# -*- coding: utf-8 -*-
"""FINAL EXAM_DANSECO

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i-Owmm5GgCDIcQKL9yBOuNhpqGs1QcVJ

# Final Examination <br>

**Objective(s):**

This activity aims to apply all the learnings for the Final Period. 

**Intended Learning Outcomes (ILOs):**

Demonstrate how to train and save a model.
Demonstrate how to deploy the deep learning model in the cloud. (not Machine Learning model) 
 

**Instructions:**

You can choose any previous deep learning model. 
Follow the instructions on deploying a model using Streamlit App in the cloud. 
 

 

Note: An accessible URL of the APP should be submitted. Also, upload the Github repo link. Strictly no straight copying from the internet.
"""

# Commented out IPython magic to ensure Python compatibility.
# Ignore the warnings
import warnings
warnings.filterwarnings('always')
warnings.filterwarnings('ignore')

# Data Analysis Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns

# Image Processing Libraries
import tensorflow as tf

# Pre processing
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Deep Learning Libraries
import keras
from keras import backend as K
from keras.models import Sequential
from keras.layers import Dense

from keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop

from keras.utils import to_categorical
from tensorflow.keras.utils import to_categorical

# CNN Libraries
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization

# Operating System Commands
import os

# Image Manipulation Library
import cv2                  
import tqdm as tqdm               
from random import shuffle  
import random 
from zipfile import ZipFile
from PIL import Image

# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

# Set the path to the directory containing the images
dir = '/content/drive/MyDrive/Colab Notebooks/DATA/Final Examination_DANSECO/Soda'

class_list = os.listdir(dir)

print("Soda :\n")

for class_name in class_list:
    
  print(class_name.upper())

# Define Class Filepaths
Pepsi = '/content/drive/MyDrive/Colab Notebooks/DATA/Final Examination_DANSECO/Soda/pepsi'
CocaCola = '/content/drive/MyDrive/Colab Notebooks/DATA/Final Examination_DANSECO/Soda/cocacola'


print("Number of Images per Class:\n")

print("Pepsi: {}".format(len(os.listdir(Pepsi))))
print("Coca Cola: {}".format(len(os.listdir(CocaCola))))

X = []
y = [] 

def make_train_dataset(directory, directory_name):
    for i in tqdm.tqdm(os.listdir(directory), colour="green"):
        full_path = os.path.join(directory, i)
        try:
            img = cv2.imread(full_path)
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img_rgb = cv2.resize(img_rgb, (128, 128))
        except:
            continue
        X.append(img_rgb)
        y.append(directory_name)
    return X, y

X, y = make_train_dataset(Pepsi, "Pepsi")
X, y = make_train_dataset(CocaCola, "Coca Cola")

fig = plt.figure(figsize=(15,8))

for i in range(15):
    sample =  random.choice(range(len(X)))
    image = X[sample]
    category = y[sample]
    plt.subplot(3,5,i+1)
    plt.subplots_adjust(hspace=0.3)
    plt.imshow(image)
    plt.xlabel(category)
    
plt.tight_layout()
plt.show()

X =  np.array(X)
y = np.array(y)
X.shape,y.shape

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
y = le.fit_transform(y)
y = to_categorical(y, 5)

X = np.array(X)
X = X/255

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

print("Training set shape:", X_train.shape, y_train.shape)
print("Test set shape:", X_test.shape, y_test.shape)

from tensorflow.keras.applications.mobilenet import MobileNet
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

def modified_model():
    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(128, 128, 3))

    model = Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dense(64, activation='relu'),
        Dense(5, activation='softmax')
    ])

    base_model.trainable = False

    opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)

    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
    return model

model = modified_model()

model.summary()

datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        zoom_range = 0.1, # Randomly zoom image 
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False)  # randomly flip images


datagen.fit(X_train)

for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, shuffle=False,
                                     ):
    # create a grid of 3x3 images
    fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(4,4))
    for i in range(3):
        for j in range(3):
            ax[i][j].imshow(X_batch[i*3+j], cmap=plt.get_cmap("gray"))
    # show the plot
    plt.show()
    break

pip install h5py

from tensorflow.keras.callbacks import ModelCheckpoint

filepath="/content/drive/MyDrive/Colab Notebooks/DATA/Final Examination_DANSECO/Model/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

modified_model().fit_generator(datagen.flow(X_train, y_train, batch_size= 75),
                              epochs=10, validation_data=(X_test, y_test), callbacks=callbacks_list,
                              verbose=1, steps_per_epoch=X_train.shape[0] // 75)

from tensorflow.keras.models import load_model

# run the test harness for evaluating a model
def run_test_harness():
	model = load_model('/content/drive/MyDrive/Colab Notebooks/DATA/Final Examination_DANSECO/Model/weights-improvement-10-0.97.hdf5')
	# evaluate model on test dataset
	_, acc = model.evaluate(X_test, y_test, verbose=0)
	print('> %.3f' % (acc * 100.0))

# entry point, run the test harness
run_test_harness()

import cv2
import numpy as np
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt

# Load saved model
saved_model = load_model("/content/drive/MyDrive/Colab Notebooks/DATA/Final Examination_DANSECO/Model/weights-improvement-10-0.97.hdf5")

# Load sample image
image = cv2.imread("/content/drive/MyDrive/Colab Notebooks/DATA/Final Examination_DANSECO/Soda/cocacola/129.jpg")
image = cv2.resize(image, (128,128))
image = image / 255.0
image = np.reshape(image, (1, 128, 128, 3))

# Make a prediction using the loaded model
predicted_probabilities = saved_model.predict(image)

predicted_class = np.argmax(predicted_probabilities)

class_labels = ["Coca Cola", "Pepsi", ]

# Print the predicted class
print("Predicted class: ", class_labels[predicted_class])

image_with_label = image.squeeze()
image_with_label = cv2.putText(image_with_label, class_labels[predicted_class], (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
plt.imshow(cv2.cvtColor(np.uint8(image_with_label*255), cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title(class_labels[predicted_class])
plt.show()

image1 = cv2.imread("/content/drive/MyDrive/Colab Notebooks/DATA/Final Examination_DANSECO/Soda/pepsi/140.jpg")
image1 = cv2.resize(image1, (128, 128))
image1 = image1 / 255.0
image1 = np.reshape(image1, (1, 128, 128, 3))

predicted_probabilities1 = saved_model.predict(image1)

predicted_class1 = np.argmax(predicted_probabilities1)

class_labels = ["Coca Cola", "Pepsi"]

# Print the predicted class
print("Predicted class: ", class_labels[predicted_class1])

image_with_label = image1.squeeze()
image_with_label = cv2.putText(image_with_label, class_labels[predicted_class1], (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
plt.imshow(cv2.cvtColor(np.uint8(image_with_label*255), cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title(class_labels[predicted_class1])
plt.show()

"""# Conclusion <br>
In conclusion, I showed how to install a deep learning model on the cloud as well as how to train and preserve a model. I have demonstrated that it is feasible to train a deep learning model locally, then deploy it for inference on the cloud. Due to the cloud's ability to offer more resources than a local computer, this may be a good technique to enhance the performance of a deep learning model. I have also demonstrated that deploying a deep learning model on the cloud is feasible without writing any code. For students like me who were are unfamiliar with cloud computing, this method is really helpful to understand this topic.

# Links:
https://www.kaggle.com/datasets/die9origephit/pepsi-and-cocacola-images
"""